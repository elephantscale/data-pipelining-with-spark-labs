{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames 1\n",
    "\n",
    "Working with Pandas and Spark dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    import findspark\n",
    "    findspark.init()  # uses SPARK_HOME\n",
    "    print(\"Spark found in : \", findspark.find())\n",
    "\n",
    "    import pyspark\n",
    "    from pyspark import SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    # use a unique tmep dir for warehouse dir, so we can run multiple spark sessions in one dir\n",
    "    import tempfile\n",
    "    tmpdir = tempfile.TemporaryDirectory()\n",
    "\n",
    "    config = ( SparkConf()\n",
    "             .setAppName(\"TestApp\")\n",
    "             .setMaster(\"local[*]\")\n",
    "             .set('executor.memory', '2g')\n",
    "             .set('spark.sql.warehouse.dir', tmpdir.name)\n",
    "             .set(\"some_property\", \"some_value\") # another example\n",
    "             )\n",
    "\n",
    "    spark = SparkSession.builder.config(conf=config).getOrCreate()\n",
    "\n",
    "print('Spark UI running on port ' + spark.sparkContext.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Create a Pandas DataFrame\n",
    "\n",
    "Here, we will create a Pandas DF and then convert it to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_df = pd.DataFrame ({'col1' : ['A', 'B', 'C', 'D'], \n",
    "                       'col2' : [10, 20, 30, 40], \n",
    "                       'col3' : [1.1, 2.2, 3.3, 4.4]})\n",
    "pd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Convert it to Spark DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(pd_df)\n",
    "spark_df.printSchema()\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Convering from Spark --> Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is spark df\n",
    "summary = spark_df.describe()\n",
    "\n",
    "summary_pd = summary.toPandas()\n",
    "\n",
    "summary_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark dataframe <--> Pandas Dataframe Conversion\n",
    "\n",
    "You can easily convert Spark DF to Pandas DF by using  `toPandas()` method.\n",
    "\n",
    "But be certain not to convert large Spark dataframes into Pandas DF.  You will run out of memory. \n",
    "\n",
    "![](../assets/images/spark-pandas-dataframe-conversion-1.png)\n",
    "\n",
    "Here `describe` gives us a summary df, which is quite small, so we can convert it to Pandas comfortably.\n",
    "\n",
    "If you are converting arbitary Spark DFs into  Pandas DFs you need to do something like this\n",
    "\n",
    "`spark_df.limit(10).toPandas()`\n",
    "\n",
    "So this way you protect yourself from converting huge DF into Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(1,10000000).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
